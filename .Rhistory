View(modelVerification)
tar_make()
tar_make()
tar_make()
tar_load(modelVerification)
View(modelVerification)
tar_load(modelVerification)
tar_make()
4/7
hist(modelVerification$baseflow_fraction_maxwell)
summary(modelVerification$baseflow_fraction_maxwell)
summary(modelVerification$baseflow_fraction_lynehollick)
summary(modelVerification$baseflow_fraction_lynehollick_singh)
tar_make()
tar_make()
2/3
625/675
mean(c(67,93))
627/678
verifyDF <- modelVerification
tar_make()
2/3
1/(21+1+68)
553/(553+29+3)
5/365
tar_make()
tar_load(modelVerification)
View(modelVerification)
tar_make()
tar_make()
tar_make()
tar_make()
tar_load(modelVerification)
View(modelVerification)
1/365
tar_make()
tar_make()
30/365
tar_make()
1/12
View(modelVerification)
t <- modelVerification[modelVerification$model_cf == 'intermittent',]
View(t)
t <- modelVerification[modelVerification$perenniality == 'intermittent',]
View(t)
tar_make()
584/(584+4+34)
365*0.083
all(c(1,2,3,4,5) < 3)
any(c(1,2,3,4,5) < 3)
View(modelVerification)
View(modelVerification)
any(c(1,2,3,4,5) > 10)
View(modelVerification)
tar_load(modelVerification)
t <- modelVerification[modelVerification$baseflow_cf == 'intermittent']
t <- modelVerification[modelVerification$baseflow_cf == 'intermittent',]
View(t)
586/(586+16+34+4+1+37)
mean(c(0.67, 0, 6))
mean(c(0.67, 0, 584/(584+38)))
tar_visnetwork()
tar_make()
tar_make()
tar_visnetwork()
tar_make()
tar_visnetwork
tar_visnetwork()
tar_visnetwork()
tar_load(rivNetFin)
tar_load(combined_rivnets)
View(combined_rivnets)
#SETUP STATIC BRANCHING----------------------------
#Each HUC4 branch gets it's own branch
mapped <- tar_map(
unlist=FALSE, #to facilitate tar_combine within a mapping scheme (see below)
values = tibble(
method_function = rlang::syms("extractWTD"),
huc4 = c('0101', '0102', '0103', '0104', '0105', '0106', '0107', '0108', '0109', '0110',
"1101", '1102', '1103', '1104', '1105', '1106', '1107', '1108', '1109', '1110', '1111', '1112', '1113', '1114',
'1201', '1202', '1203', '1204', '1205', '1206', '1207', '1208', '1209', '1210', '1211'),
# '1301', '1302', '1303', '1304', '1305', '1306', '1307', '1308', '1309',
#  '1601', '1602', '1603', '1604', '1605', '1606')
),
names = "huc4",
tar_target(extractedRivNet, method_function(path_to_data, huc4)), #extract water table depths along the river reaches
tar_target(rivNetFin, getPerenniality(extractedRivNet, huc4, threshold, error, 'mean', widAHG)), #calculate perenniality using mean water table depth along the reach
tar_target(rivNetFin_verify, getRivNetverify(rivNetFin, nhdGages, USGS_data)),
tar_target(results, collectResults(rivNetFin, huc4))) #aggregate HUC4 results
View(mapped)
tar_visnetwork()
tar_visnetwork(targets_only = T)
tar_visnetwork()
tar_visnetwork()
tar_prune()
tar_visnetwork(targets_only = T)
tar_make_clustermq(workers=4)
tar_load(rivNetFin_0101)
tar_load(rivNetFin_1205)
tar_load(rivNetFin_verify_1205)
tar_load(rivNetFin_verify_0101)
tar_visnetwork()
nrow(rivNetFin_verify_1205)
View(rivNetFin_verify_0101)
View(rivNetFin_verify_1205)
View(rivNetFin_verify_1205)
tar_make_clustermq(workers=4)
tar_visnetwork()
tar_load(combined_verify)
View(combined_verify)
tar_visnetwork()
tar_make()
tar_load(combined_verify)
tar_load(combined_results)
View(combined_results)
sum(combined_results$totalephmeralQ)/sum(combined_results$totalperennialQ+combined_results$totalephmeralQ+combined_results$totalintermittentQ)
mean(combined_results$percQ_eph)
mean(combined_results$percSA_eph)
tar_validate()
tar_visnetwork(targets_only = T)
tar_make_clustermq(workers=5)
source("C:/Users/craig/OneDrive - University of Massachusetts/Ongoing Projects/CONUS_ephemeral/src/hydrographCheck.R", echo=TRUE)
library(readr)
write_rds(listPlots, 'cache/true_ephemerals.rds')
listPlots
85/87
2/87
tar_make()
source("C:/Users/craig/OneDrive - University of Massachusetts/Ongoing Projects/CONUS_ephemeral/src/hydrographCheck.R", echo=TRUE)
listPlots
listPlots
View(summ)
View(summ)
tar_make()
listPlots
source("C:/Users/craig/OneDrive - University of Massachusetts/Ongoing Projects/CONUS_ephemeral/src/hydrographCheck.R", echo=TRUE)
listPlots
tar_make()
tar_make()
tar_make()
tar_make_clustermq(workers=4)
library(targets)
tar_make()
tar_make_clustermq(workers=4)
tar_make_clustermq(workers=4)
tar_make_clustermq(workers=4)
tar_make()
tar_make()
tar_make()
source("C:/Users/craig/OneDrive - University of Massachusetts/Ongoing Projects/CONUS_ephemeral/src/hydrographCheck.R", echo=TRUE)
source("C:/Users/craig/OneDrive - University of Massachusetts/Ongoing Projects/CONUS_ephemeral/src/hydrographCheck.R", echo=TRUE)
source("C:/Users/craig/OneDrive - University of Massachusetts/Ongoing Projects/CONUS_ephemeral/src/hydrographCheck.R", echo=TRUE)
write_rds(listPlots, 'cache/false_positives.rds')
listPlots[[10]]
listPlots[[12]]
listPlots[[13]]
(743+2+5)/(743+2+5+89)
2/3
tar_make()
750/(750+89)
752/(750+89+3)
tar_load(combined_results)
library(targets)
tar_load(combined_results)
View(combined_results)
hist(combined_results$percQ_eph)
750/(750+89)
View(combined_results)
tar_load(combined_verify)
View(combined_verify)
falsePos <- combined_verify[combined_verify$baseflow_cf == 'perennial' & combined_verify$model_cf == 'ephemeral',]
truePos <- combined_verify[combined_verify$baseflow_cf == 'ephemeral' & combined_verify$model_cf == 'ephemeral',]
View(truePos)
View(falsePos)
options(scipen = 999)
View(falsePos)
hist(falsePos$alpha)
summary(falsePos$alpha)
tar_make()
tar_make()
View(truePos)
truePos <- combined_verify[combined_verify$baseflow_cf == 'ephemeral' & combined_verify$model_cf == 'perennial',]
d <- combined_verify[combined_verify$baseflow_cf == 'perennial' & combined_verify$model_cf == 'perennial',]
summary(d$alpha)
summary(falsePos$alpha)
View(falsePos)
View(combined_verify)
install.packages('baseflow')
library(baseflow)
vignette(baseflow)
vignette('baseflow')
vignette(package=baseflow)
vignette(package='baseflow')
remove.packages('baseflow')
library(readr)
meansLandCover_01 <- read_csv("C:/Users/craig/OneDrive - University of Massachusetts/Ongoing Projects/CONUS_CO2_prep/for_intermittency_project/meansLandCover_01.csv")
View(meansLandCover_01)
View(combined_verify)
tar_visnetwork()
tar_make_clustermq(wrokers=4)
tar_make_clustermq(workers=4)
794/(794+45)
796/(796+1+45)
mean(c(0.67, 0.95))
tar_make()
tar_load(combined_verify)
t <- combined_verify[combined_verify$baseflow_cf == 'perennial' & combined_verify$perenniality == 'ephemeral',]
View(t)
i <- combined_verify[combined_verify$baseflow_cf == 'perennial' & combined_verify$perenniality == 'intermittent',]
View(i)
View(t)
tar_make_clustermq(workers=4)
tar_load(combined_results)
View(combined_results)
tar_visnetwork()
renv::snapshot()
tar_prune()
library(targets)
tar_visnetwork()
#' @note Be aware of the expilict repo structure within the data repo, i.e. even though the user specifies the path to the data repo, there are assumed internal folders.
#'
#' @param path_to_data: data repo path directory
#' @param huc4: huc basin level 4 code
#'
#' @import terra
#' @import sf
#' @import dplyr
#'
#' @return NHD hydrograpy with mean monthly water table depths attached.
extractWTD <- function(path_to_data, huc4){
huc2 <- substr(huc4, 1, 2)
#get basin to clip wtd model
basins <- vect(paste0(path_to_data, '\\HUC2_', huc2, '\\WBD_', huc2, '_HU2_Shape\\Shape\\WBDHU4.shp')) #basin polygon
#Process-based water table depth modeling Fan etal 2013 (updated in 2020: doi:10.1126/science.1229881)
#monthly averages for hourly model runs for 2004-2014
wtd <- rast(paste0(path_to_data, '/for_ephemeral_project/NAMERICA_WTD_monthlymeans.nc'))
#USGS NHD
dsnPath <- paste0(path_to_data, '\\HUC2_', huc2, '\\NHDPLUS_H_', huc4, '_HU4_GDB\\NHDPLUS_H_', huc4, '_HU4_GDB.gdb')
nhd <- st_read(dsn=dsnPath, layer='NHDFlowline', quiet=TRUE)
NHD_HR_EROM <- st_read(dsn = dsnPath, layer = "NHDPlusEROMMA", quiet=TRUE) #mean annual flow table
#NHD_HR_ROMA <- st_read(dsn = dsnPath, layer='NHDPlusIncrROMA')
NHD_HR_VAA <- st_read(dsn = dsnPath, layer = "NHDPlusFlowlineVAA", quiet=TRUE) #additional 'value-added' attributes
basin <- basins[basins$huc4 == huc4,]
#clip wtd data to basin at hand
wtd <- crop(wtd, basin)
nhd <- left_join(nhd, NHD_HR_EROM, by='NHDPlusID')
nhd <- left_join(nhd, NHD_HR_VAA, by='NHDPlusID')
nhd$Q_cms <- nhd$QEMA * 0.0283 #cfs to cms
nhd <- filter(nhd, StreamCalc > 0 & Q_cms > 0) #no pipelines, connectors, canals. Only rivers/streams and 'artificial paths', ie.e. lake throughflow lines. Also- even epehmeral streams should have a mean annual flow > 0...
nhd <- vect(nhd)
nhd_wtd_01 <- extract(wtd$WTD_1, nhd, fun=summariseWTD)
nhd_wtd_02 <- extract(wtd$WTD_2, nhd, fun=summariseWTD)
nhd_wtd_03<- extract(wtd$WTD_3, nhd, fun=summariseWTD)
nhd_wtd_04 <- extract(wtd$WTD_4, nhd, fun=summariseWTD)
nhd_wtd_05 <- extract(wtd$WTD_5, nhd, fun=summariseWTD)
nhd_wtd_06<- extract(wtd$WTD_6, nhd, fun=summariseWTD)
nhd_wtd_07 <- extract(wtd$WTD_7, nhd, fun=summariseWTD)
nhd_wtd_08 <- extract(wtd$WTD_8, nhd, fun=summariseWTD)
nhd_wtd_09 <- extract(wtd$WTD_9, nhd, fun=summariseWTD)
nhd_wtd_10 <- extract(wtd$WTD_10, nhd, fun=summariseWTD)
nhd_wtd_11<- extract(wtd$WTD_11, nhd, fun=summariseWTD)
nhd_wtd_12 <- extract(wtd$WTD_12, nhd, fun=summariseWTD)
nhd_df <- as.data.frame(nhd)
nhd_df <- select(nhd_df, c('NHDPlusID', 'StreamOrde', 'HydroSeq', 'FromNode', 'ToNode','Q_cms', 'LengthKM'))
nhd_df$wtd_m_min_01 <- as.numeric(nhd_wtd_01$WTD_1.min)
nhd_df$wtd_m_median_01 <- as.numeric(nhd_wtd_01$WTD_1.median)
nhd_df$wtd_m_mean_01 <- as.numeric(nhd_wtd_01$WTD_1.mean)
nhd_df$wtd_m_max_01 <- as.numeric(nhd_wtd_01$WTD_1.max)
nhd_df$wtd_m_min_02 <- as.numeric(nhd_wtd_02$WTD_2.min)
nhd_df$wtd_m_median_02 <- as.numeric(nhd_wtd_02$WTD_2.median)
nhd_df$wtd_m_mean_02 <- as.numeric(nhd_wtd_02$WTD_2.mean)
nhd_df$wtd_m_max_02 <- as.numeric(nhd_wtd_02$WTD_2.max)
nhd_df$wtd_m_min_03 <- as.numeric(nhd_wtd_03$WTD_3.min)
nhd_df$wtd_m_median_03 <- as.numeric(nhd_wtd_03$WTD_3.median)
nhd_df$wtd_m_mean_03 <- as.numeric(nhd_wtd_03$WTD_3.mean)
nhd_df$wtd_m_max_03 <- as.numeric(nhd_wtd_03$WTD_3.max)
nhd_df$wtd_m_min_04 <- as.numeric(nhd_wtd_04$WTD_4.min)
nhd_df$wtd_m_median_04 <- as.numeric(nhd_wtd_04$WTD_4.median)
nhd_df$wtd_m_mean_04 <- as.numeric(nhd_wtd_04$WTD_4.mean)
nhd_df$wtd_m_max_04 <- as.numeric(nhd_wtd_04$WTD_4.max)
nhd_df$wtd_m_min_05 <- as.numeric(nhd_wtd_05$WTD_5.min)
nhd_df$wtd_m_median_05 <- as.numeric(nhd_wtd_05$WTD_5.median)
nhd_df$wtd_m_mean_05 <- as.numeric(nhd_wtd_05$WTD_5.mean)
nhd_df$wtd_m_max_05 <- as.numeric(nhd_wtd_05$WTD_5.max)
nhd_df$wtd_m_min_06 <- as.numeric(nhd_wtd_06$WTD_6.min)
nhd_df$wtd_m_median_06 <- as.numeric(nhd_wtd_06$WTD_6.median)
nhd_df$wtd_m_mean_06 <- as.numeric(nhd_wtd_06$WTD_6.mean)
nhd_df$wtd_m_max_06 <- as.numeric(nhd_wtd_06$WTD_6.max)
nhd_df$wtd_m_min_07 <- as.numeric(nhd_wtd_07$WTD_7.min)
nhd_df$wtd_m_median_07 <- as.numeric(nhd_wtd_07$WTD_7.median)
nhd_df$wtd_m_mean_07 <- as.numeric(nhd_wtd_07$WTD_7.mean)
nhd_df$wtd_m_max_07 <- as.numeric(nhd_wtd_07$WTD_7.max)
nhd_df$wtd_m_min_08 <- as.numeric(nhd_wtd_08$WTD_8.min)
nhd_df$wtd_m_median_08 <- as.numeric(nhd_wtd_08$WTD_8.median)
nhd_df$wtd_m_mean_08 <- as.numeric(nhd_wtd_08$WTD_8.mean)
nhd_df$wtd_m_max_08 <- as.numeric(nhd_wtd_08$WTD_8.max)
nhd_df$wtd_m_min_09 <- as.numeric(nhd_wtd_09$WTD_9.min)
nhd_df$wtd_m_median_09 <- as.numeric(nhd_wtd_09$WTD_9.median)
nhd_df$wtd_m_mean_09 <- as.numeric(nhd_wtd_09$WTD_9.mean)
nhd_df$wtd_m_max_09 <- as.numeric(nhd_wtd_09$WTD_9.max)
nhd_df$wtd_m_min_10 <- as.numeric(nhd_wtd_10$WTD_10.min)
nhd_df$wtd_m_median_10 <- as.numeric(nhd_wtd_10$WTD_10.median)
nhd_df$wtd_m_mean_10 <- as.numeric(nhd_wtd_10$WTD_10.mean)
nhd_df$wtd_m_max_10 <- as.numeric(nhd_wtd_10$WTD_10.max)
nhd_df$wtd_m_min_11 <- as.numeric(nhd_wtd_11$WTD_11.min)
nhd_df$wtd_m_median_11 <- as.numeric(nhd_wtd_11$WTD_11.median)
nhd_df$wtd_m_mean_11 <- as.numeric(nhd_wtd_11$WTD_11.mean)
nhd_df$wtd_m_max_11 <- as.numeric(nhd_wtd_11$WTD_11.max)
nhd_df$wtd_m_min_12 <- as.numeric(nhd_wtd_12$WTD_12.min)
nhd_df$wtd_m_median_12 <- as.numeric(nhd_wtd_12$WTD_12.median)
nhd_df$wtd_m_mean_12 <- as.numeric(nhd_wtd_12$WTD_12.mean)
nhd_df$wtd_m_max_12 <- as.numeric(nhd_wtd_12$WTD_12.max)
return(nhd_df)
}
start <- Sys.time()
#############USER INPUTS-------------------
path_to_data <- 'C:\\Users\\craig\\OneDrive - University of Massachusetts\\Ongoing Projects\\CONUS_CO2_prep' #path to data repo (separate from code repo)
huc4 <- '0108'
t <- extractWTD(path_to_data, huc4)
library(vect)
library(terra)
library(sf)
library(dplyr)
library(readr)
start <- Sys.time()
t <- extractWTD(path_to_data, huc4)
source("C:/Users/craig/OneDrive - University of Massachusetts/Ongoing Projects/CONUS_ephemeral/src/utils.R", echo=TRUE)
start <- Sys.time()
t <- extractWTD(path_to_data, huc4)
end <- Sys.time()
end - start
library(targets)
tar_visnetwork()
library(targets)
tar_visnetwork()
tar_make_clustermq(workers=3)
tar_make_clustermq(workers=3)
tar_make_clustermq(workers=3)
tar_make_clustermq(workers=3)
#############USER INPUTS-------------------
path_to_data <- 'C:/Users/craig/OneDrive - University of Massachusetts/Ongoing Projects/CONUS_CO2_prep'#'/nas/cee-water/cjgleason/craig/CONUS_ephemeral_data' #path to data repo (separate from code repo)
huc4 <- '1101'
huc2 <- substr(huc4, 1, 2)
#get basin to clip wtd model
basins <- vect(paste0(path_to_data, '/HUC2_', huc2, '/WBD_', huc2, '_HU2_Shape/Shape/WBDHU4.shp')) #basin polygon
library(terra)
library(sf)
#get basin to clip wtd model
basins <- vect(paste0(path_to_data, '/HUC2_', huc2, '/WBD_', huc2, '_HU2_Shape/Shape/WBDHU4.shp')) #basin polygon
#Process-based water table depth modeling Fan etal 2013 (updated in 2020: doi:10.1126/science.1229881)
#monthly averages for hourly model runs for 2004-2014
wtd <- rast(paste0(path_to_data, '/for_ephemeral_project/NAMERICA_WTD_monthlymeans.nc'))
#USGS NHD
dsnPath <- paste0(path_to_data, '/HUC2_', huc2, '/NHDPLUS_H_', huc4, '_HU4_GDB/NHDPLUS_H_', huc4, '_HU4_GDB.gdb')
nhd <- st_read(dsn=dsnPath, layer='NHDFlowline', quiet=TRUE)
lakes <- as.data.frame(st_read(dsn=dsnPath, layer='NHDWaterbody', quiet=TRUE)) %>%
dplyr::filter(FType %in% c(390, 436)) #lakes/reservoirs only
colnames(lakes)[6] <- 'LakeAreaSqKm'
NHD_HR_EROM <- st_read(dsn = dsnPath, layer = "NHDPlusEROMMA", quiet=TRUE) #mean annual flow table
NHD_HR_VAA <- st_read(dsn = dsnPath, layer = "NHDPlusFlowlineVAA", quiet=TRUE) #additional 'value-added' attributes
basin <- basins[basins$huc4 == huc4,]
#clip wtd data to basin at hand
wtd <- crop(wtd, basin)
library(dplyr)
nhd <- left_join(nhd, lakes, by=c('WBArea_Permanent_Identifier'='Permanent_Identifier'))
colnames(nhd)[16] <- 'NHDPlusID' #some manual rewriting b/c this columns get doubled from previous joins where data was needed for specific GIS tasks...
nhd <- left_join(nhd, NHD_HR_EROM, by='NHDPlusID')
nhd <- left_join(nhd, NHD_HR_VAA, by='NHDPlusID')
nhd$Q_cms <- nhd$QEMA * 0.0283 #cfs to cms
nhd$waterbody <- ifelse(is.na(nhd$WBArea_Permanent_Identifier)==0 & is.na(nhd$LakeAreaSqKm) == 0 & nhd$LakeAreaSqKm > 0, 'Lake/Reservoir', 'River') #assign waterbody type for depth modeling
nhd <- filter(nhd, StreamCalc > 0 & Q_cms > 0) #no pipelines, connectors, canals. Only rivers/streams and 'artificial paths', ie.e. lake throughflow lines. Also- even epehmeral streams should have a mean annual flow > 0...
#calculate depths and widths via hydraulic geomtery and lake volume modeling
nhd$lakeVol_m3 <- 0.533 * (nhd$LakeAreaSqKm*1e6)^1.204 #Cael et al. 2016 function
#Calculate and assign lake percents to each throughflow line so that we have fracVols and fracSAs for each throughflow line
#This is based on reachLength/total throughflow line reach length
sumThroughFlow <- filter(as.data.frame(nhd), is.na(WBArea_Permanent_Identifier)==0) %>%
group_by(WBArea_Permanent_Identifier) %>%
summarise(sumThroughFlow = sum(LengthKM))
nhd <- left_join(nhd, sumThroughFlow, by='WBArea_Permanent_Identifier')
nhd$lakePercent <- nhd$LengthKM / nhd$sumThroughFlow
nhd$frac_lakeVol_m3 <- nhd$lakeVol_m3 * nhd$lakePercent
nhd$frac_lakeSurfaceArea_m2 <- nhd$LakeAreaSqKm * nhd$lakePercent * 1e6
nhd$depth_m <- mapply(depth_func, nhd$waterbody, nhd$Q_cms, nhd$lakeVol_m3, nhd$LakeAreaSqKm*1e6)
source("C:/Users/craig/OneDrive - University of Massachusetts/Ongoing Projects/CONUS_ephemeral/src/utils.R", echo=TRUE)
nhd$depth_m <- mapply(depth_func, nhd$waterbody, nhd$Q_cms, nhd$lakeVol_m3, nhd$LakeAreaSqKm*1e6)
source("C:/Users/craig/OneDrive - University of Massachusetts/Ongoing Projects/CONUS_ephemeral/src/utils.R", echo=TRUE)
nhd$depth_m <- mapply(depth_func, nhd$waterbody, nhd$Q_cms, nhd$lakeVol_m3, nhd$LakeAreaSqKm*1e6)
widAHG <- readr::read_rds('C:/Users/craig/OneDrive - University of Massachusetts/Ongoing Projects/RSK600/cache/widAHG.rds') #width AHG model
#' width for rivers
#'
#' @param waterbody: flag for whether reach is a river or lake/reservoir #[1/0]
#' @param Q: discharge [m3/s]
#' @param widAHG: width~Q AHG model from Brinkerhoff et al (in review GBC)
#'
#' @return river width via hydraulic geometry [m]
width_func <- function(waterbody, Q, widAHG){
if (waterbody == 'River') {
output <- exp(widAHG$coefficients[1])*Q^(widAHG$coefficients[2])
}
else {
output <- NA #river width makes no sense in lakes so don't do it!
}
return(output)
}
nhd$width_m <- mapply(width_func, nhd$waterbody, nhd$Q_cms, widAHG)
source("C:/Users/craig/OneDrive - University of Massachusetts/Ongoing Projects/CONUS_ephemeral/src/utils.R", echo=TRUE)
nhd$width_m <- mapply(width_func, nhd$waterbody, nhd$Q_cms)
source("C:/Users/craig/OneDrive - University of Massachusetts/Ongoing Projects/CONUS_ephemeral/src/utils.R", echo=TRUE)
nhd$width_m <- mapply(width_func, nhd$waterbody, nhd$Q_cms)
source("C:/Users/craig/OneDrive - University of Massachusetts/Ongoing Projects/CONUS_ephemeral/src/utils.R", echo=TRUE)
nhd$width_m <- mapply(width_func, nhd$waterbody, nhd$Q_cms)
tar_make_clustermq(workers=3)
widAHG$coefficients
depAHG <- readr::read_rds('C:/Users/craig/OneDrive - University of Massachusetts/Ongoing Projects/RSK600/cache/depAHG.rds') #depth AHG model
tar_make_clustermq(workers=3)
tar_make_clustermq(workers=3)
tar_make_clustermq(workers=3)
tar_make_clustermq(workers=3)
tar_make_clustermq(workers=3)
library(targets)
library(targets)
tar_load(rivNetFin_1301)
tar_load(rivNetFin_1302)
tar_load(rivNetFin_1303)
tar_load(rivNetFin_1304)
tar_load(rivNetFin_1305)
tar_load(rivNetFin_1306)
tar_load(rivNetFin_1307)
tar_load(rivNetFin_1308)
tar_load(rivNetFin_1309)
df_13 <- rbind(rivNetFin_1301,rivNetFin_1302,rivNetFin_1303,rivNetFin_1304,rivNetFin_1305,rivNetFin_1306,rivNetFin_1307,rivNetFin_1308,rivNetFin_1309)
nhd_df <- df_13
ephQ_init <- nhd_df %>%
mutate(perenniality = ifelse(StreamOrde ==9, 'perennial', perenniality))%>% #just dummy for now to handle rio grande
mutate(reduced_perenniality = ifelse(perenniality == 'perennial', 'nonEph', perenniality))%>% #consder perennial and nonEph as one
filter(reduced_perenniality %in% c('ephemeral', 'nonEph')) %>% #remove 'dry channels'
mutate(Q_bin = cut(Q_cms, breaks=seq(10^-2, 10^2, 0.1))) %>%
group_by(Q_bin, reduced_perenniality) %>%
summarise(sumQ = sum(Q_cms))
library(dplyr)
ephQ_init <- nhd_df %>%
mutate(perenniality = ifelse(StreamOrde ==9, 'perennial', perenniality))%>% #just dummy for now to handle rio grande
mutate(reduced_perenniality = ifelse(perenniality == 'perennial', 'nonEph', perenniality))%>% #consder perennial and nonEph as one
filter(reduced_perenniality %in% c('ephemeral', 'nonEph')) %>% #remove 'dry channels'
mutate(Q_bin = cut(Q_cms, breaks=seq(10^-2, 10^2, 0.1))) %>%
group_by(Q_bin, reduced_perenniality) %>%
summarise(sumQ = sum(Q_cms))
forExtrapolation <- ephQ_init %>%
group_by(Q_bin) %>%
summarise(totalQ =sum(sumQ))
ephQ <- ephQ_init %>%
filter(reduced_perenniality == 'ephemeral') %>%
rename(ephQ= sumQ) %>%
select(!'reduced_perenniality')
forExtrapolation <- left_join(forExtrapolation, ephQ, by='Q_bin')
forExtrapolation$ephQ <- ifelse(is.na(forExtrapolation$ephQ)==1, 0, forExtrapolation$ephQ)
forExtrapolation$percQ_eph <- forExtrapolation$ephQ/forExtrapolation$totalQ
forExtrapolation <- forExtrapolation[-nrow(forExtrapolation),]
forExtrapolation$Q_bin <- str_extract(as.character(forExtrapolation$Q_bin), ",\\s*(.*?)\\s*]")
forExtrapolation$Q_bin <- as.numeric(substr(forExtrapolation$Q_bin, 2, nchar(forExtrapolation$Q_bin)-1))
library(stringr)
forExtrapolation$Q_bin <- str_extract(as.character(forExtrapolation$Q_bin), ",\\s*(.*?)\\s*]")
forExtrapolation$Q_bin <- as.numeric(substr(forExtrapolation$Q_bin, 2, nchar(forExtrapolation$Q_bin)-1))
library(ggplot2)
ggplot(forExtrapolation, aes(x=Q_bin, y=percQ_eph))+
geom_point(size=3)+
geom_smooth(method='gam')+
coord_cartesian(xlim=c(0.00405, 100),ylim=c(0,1)) +
scale_x_log10()
View(forExtrapolation)
View(ephQ_init)
ephQ_init <- nhd_df %>%
mutate(perenniality = ifelse(StreamOrde ==9, 'perennial', perenniality))%>% #just dummy for now to handle rio grande
mutate(reduced_perenniality = ifelse(perenniality == 'perennial', 'nonEph', perenniality))%>% #consder perennial and nonEph as one
filter(reduced_perenniality %in% c('ephemeral', 'nonEph')) %>% #remove 'dry channels'
mutate(Q_bin = cut(Q_cms, breaks=seq(10^-2, 10^2, 0.1))) %>%
group_by(Q_bin, reduced_perenniality) %>%
summarise(sumQ = sum(Q_cms))
forExtrapolation <- ephQ_init %>%
group_by(Q_bin) %>%
summarise(totalQ =sum(sumQ))
ephQ <- ephQ_init %>%
filter(reduced_perenniality == 'ephemeral') %>%
rename(ephQ= sumQ) %>%
select(!'reduced_perenniality')
View(ephQ_init)
View(ephQ_init)
ephQ <- ephQ_init %>%
filter(reduced_perenniality == 'ephemeral') %>%
rename(ephQ= sumQ) %>%
select(!'reduced_perenniality')
View(forExtrapolation)
ephQ <- ephQ_init %>%
filter(reduced_perenniality == 'ephemeral') %>%
rename(ephQ= sumQ) %>%
select(!'reduced_perenniality')
View(ephQ_init)
ephQ_init <- nhd_df %>%
# mutate(perenniality = ifelse(StreamOrde ==9, 'perennial', perenniality))%>% #just dummy for now to handle rio grande
mutate(reduced_perenniality = ifelse(perenniality == 'perennial', 'nonEph', perenniality))%>% #consder perennial and nonEph as one
filter(reduced_perenniality %in% c('ephemeral', 'nonEph')) %>% #remove 'dry channels'
mutate(Q_bin = cut(Q_cms, breaks=seq(10^-2, 10^2, 0.1))) %>%
group_by(Q_bin, reduced_perenniality) %>%
summarise(sumQ = sum(Q_cms))
forExtrapolation <- ephQ_init %>%
group_by(Q_bin) %>%
summarise(totalQ =sum(sumQ))
ephQ <- ephQ_init %>%
filter(reduced_perenniality == 'ephemeral') %>%
rename(ephQ= sumQ) %>%
select(!'reduced_perenniality')
View(ephQ_init)
