---
title: "Results Report"
output:
  rmdformats::downcute
date: "`r Sys.Date()`"
author: 'Craig Brinkerhoff'
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
options(tidyverse.quiet = TRUE)
library(targets)
library(ggplot2)
theme_set(theme_classic())
```


**Note:** This report contains all of the results generated by the project pipeline. Most of these results are also written to file in `cache/` but for the sake of report reproducibility we pull directly from the analysis pipeline.

## **Background**
In 2020, the Trump administration passed the 'Navigable Waters Protection Act' (NWPA) to "more clearly define" the waters of the United States (WOTUS). WOTUS serves as the hydrography backbone for the Clean Water Act, determining which hydrological features fall under Clean Water Act jurisdiction (and all that that entails).

The Trump-era NWPA makes clear these definitions by explicitly removing WOTUS status from 'ephemeral streams', those that only flow after precipitation events. In *Pascua Yaqui Tribe v. U.S. Environmental Protection Agency*, the legality of the NWPA was questioned and has risen to the United States Supreme Court. Because of this, implementation of the NWPA has currently halted.

Here, we model where these ephemeral streams are across the United States, and quantify the downstream impact that the NWPA would have on streamflow.

## **Model Overview**
![Model overview. Green are existing datasets, purple are our model, yellow is model robustness testing, and blue is the ultimate result/goal of the analysis.](/nas/cee-water/cjgleason/craig/CONUS_ephemeral/docs/workflow.png)

## **Parameter Setup**
Parameters with ranges listed will be described in greater detail in `Results: Parameter Sensitivity` section.

| Parameter                              | Type   | Nature   | Description                                                                                                                                     | Tested        |
|----------------------------------------|--------|----------|-------------------------------------------------------------------------------------------------------------------------------------------------|---------------|
| Water Table Threshold                  | Single | Meta     | Small buffer around the free surface                                                                                                            | 10cm          |
| Snapping Threshold                     | Single | Meta     | Distance buffer to assign field data to river reaches                                                                                           | 1-50m         |
| Non-Ephemeral Flow Frequency Threshold | Single | Meta     | Minimum % of year that non-ephemeral streamgauges can run dry                                                                                   | 5%            |
| Runoff ratio scalar                    | Single | Physical | % scalar to perturb runoff ratio data                                                                                                           | -35%, 0%, 35% |
| Runoff memory                          | Lumped | Physical | 'Memory in the basin-scale runoff system',  i.e. captures delayed throughflow + delayed overland flow +  general antecedent moisture conditions | 0, 1, 7 dys   |
| Minimum runoff threshold               | Single | Physical | Minimum runoff necessary to generate streamflow                                                                                                 | 0.24 mm/day   |

## **Current Caveats**
- 'Ephemeral channels' refers to U.S. ephemeral streams under consideration of losing WOTUS status. Canadian and Mexican ephemeral streams are not included in this category as they are outside of WOTUS status.
  - However, all Canadian and Mexican streams flowing into the U.S. are included in the model as streams not effected by the NWPA.
  - Same with canals/ditches/ponds. Included in the initial water table modeling but then excluded from final 'ephemeral/not ephemeral classification'
- 3 basins in Michigan/New York/Ontario and 1 basin in Montana/Alberta have no USGS gauges (and thus runoff data). I annually set their runoff terms to those for the 'most reasonable adjacent basin', i.e. 0904 won't be set to the adjacent basin over the Continental Divide...
- There is a quirk in the NHD data for the state of Indiana where 1-2 extra stream orders of river segments were added to the NHD, creating unrealisitic drainage densities in the hydrography, artifically defined by the state boundary. While this might be ok for modeling ephemeral channels, basin hydrographs are unrealistic because the basins cross the state boundary, creating way too dense network on one side and not-so-dense network on the other side. So, I manually removed stream orders until the 'in-Indiana' part of the river network visually matched the density of the 'out-of-Indiana' part of the river network. For these basins, this was generally 1 or 2 orders removed. We then did the rest of the modeling as normal.
- Ultimately, the model was run using a runoff memory of 1 day (i.e. given a rain event, streamflow is produced for 1 day via delayed arrival of overland flow and throughflow). This was informed by common knowledge that arid ephemeral runoff memory is usually < 1 day, but in the Eastern US it has been reported as generally around 2 days (North Carolina).

## **Results: Validation**
### *Mapping Ephemeral Channels*
Below is a confusion matrix detailing overall ability to correctly identify ephemeral features (green is good, grey is bad). Following are classification performance metrics
```{r, echo=FALSE, fig.height=7, fig.width=9}
tar_load(cfMatrix)
cfMatrix
```
```{r, echo=FALSE}
tar_load(validationResults)
out <- validationResults$validation_fin

TP <- ifelse(out$distinction == 'ephemeral' & out$perenniality == 'ephemeral', 1, 0)
FP <- ifelse(out$distinction == 'non_ephemeral' & out$perenniality == 'ephemeral', 1, 0)
TN <- ifelse(out$distinction == 'non_ephemeral' & out$perenniality == 'non_ephemeral', 1, 0)
FN <- ifelse(out$distinction == 'ephemeral' & out$perenniality == 'non_ephemeral', 1, 0)

accuracy <- round((sum(TP, na.rm=T) + sum(TN, na.rm=T))/(sum(TP, na.rm=T) + sum(TN, na.rm=T) + sum(FN, na.rm=T) + sum(FP, na.rm=T)),2)
sensitivity = round(sum(TP, na.rm=T)/(sum(TP,na.rm=T)+sum(FN,na.rm=T)),2) #also referred to as recall
specificity = round(sum(TN, na.rm=T)/(sum(TN,na.rm=T)+sum(FP,na.rm=T)),2)
precision = round(sum(TP,na.rm=T) / (sum(TP,na.rm=T) + sum(FP, na.rm=T)),2)

balAccuracy <- (sensitivity + specificity)/2
TSS = round(sensitivity + specificity - 1, 2) #Allouche etal 2006, used in CONUS ephemeral mapping by Fesenmyer etal 2021
F1 <- 2 * ((precision*sensitivity)/(precision + sensitivity))

paste0('% accuracy: ', accuracy)
paste0('% balanced accuracy: ', balAccuracy)
paste0('sensitivity: ', sensitivity)
paste0('specificity: ', specificity)
paste0('precision: ', precision)
paste0('TSS: ', TSS)
paste0('F1: ', F1)
```

This assessment is more useful regionally, to identify trends:
```{r, echo=FALSE}
tar_load(val_shapefile_fin)
paste0('Regional average % accuracy: ', round(val_shapefile_fin$average_regional_acc,2))
paste0('Regional average % balanced accuracy: ', round(val_shapefile_fin$average_regional_bal_acc,2))
paste0('Regional average sensitivity: ', round(val_shapefile_fin$average_regional_sens,2))
paste0('Regional average specificity/recall: ', round(val_shapefile_fin$average_regional_spec,2))
paste0('Regional average precision: ', round(val_shapefile_fin$average_regional_prec,2))
paste0('Regional average TSS: ', round(val_shapefile_fin$average_regional_TSS,2))
paste0('Regional average F1: ', round(val_shapefile_fin$average_regional_F1,2))

ggplot(val_shapefile_fin$shapefile, aes(fill=basinAccuracy)) +
    geom_sf(color='black') +
    viridis::scale_fill_viridis(limits = c(0, 1)) +
    ggtitle("Accuracy") +
    theme(legend.position='bottom')

ggplot(val_shapefile_fin$shapefile, aes(fill=basinTSS)) +
    geom_sf(color='black') +
    viridis::scale_fill_viridis(limits = c(0, 1)) +
    ggtitle("True Skill Statistic") +
    theme(legend.position='bottom')

df <- val_shapefile_fin$shapefile
forPlot <- tidyr::gather(df, key=key, value=value, c('basinAccuracy', 'basinSensitivity', 'basinSpecificity', 'basinTSS'))

ggplot(forPlot, aes(x=key, fill=key, y=value)) +
    geom_boxplot(color='black', size=1)
```

### *Individual Model Components*
Below is validation of the river discharge model at streamgauges across the entire US. 'Gage flow' refers to the model after adjustment to truth at each gauge. 'Ungauged flow' refers to a more realistic validation representative of the vast majority of (ungauged) rivers, where there is no gauge to inform the model.
```{r, echo=FALSE, fig.height=11, fig.width=10}
tar_load(EROM_figure)
EROM_figure
```

### *Number of Flowing Days*
Below is a coarse verification of our estimates of basin-scale, average number of flowing days in ephemeral streams. Note that data on this property is incredibly sparse and so the best we can do is verify that the orders of magnitude are reasonable. We can then do a sensitivity analysis to confirm that orders of magnitude are sufficient (below).
The purple point (in the Duke Research Forest in North Carolina) is technically measuring flow frequency in an intermittent channel that has only ephemeral streams upstream. So, it is going to be relatively underestimated by our model, as the intermittent gauged reach has some groundwater influence. This is clearly borne out in the plot.
```{r, echo=FALSE, fig.height=8, fig.width=9}
tar_load(flowingDaysValidation_fig)
flowingDaysValidation_fig
```

## **Results: Model**
### *CONUS wide influence of ephemeral streams*
Below is the % of streamflow that passes through all CONUS ephemeral features when flowing.
```{r, echo=FALSE}
tar_load(combined_results)
sum(combined_results$totalephmeralQ_flowing_scaled) / sum(combined_results$totalephmeralQ_flowing_scaled + combined_results$totalNotEphQ)
```
Below is the % of network length that is ephemeral
```{r, echo=FALSE}
tar_load(combined_results)
sum(combined_results$ephemeralNetworkLength) / sum(combined_results$ephemeralNetworkLength + combined_results$notEphNetworkLength)
```

### *Basin-scale influence of ephemeral streams*
Below is the same result, but done out for each basin to identify regional trends (numbers, followed by boxplot).
```{r, echo=FALSE, fig.height=8, fig.width=9}
tar_load(combined_results)
summary(combined_results$percQ_eph_flowing_scaled)
tar_load(boxplotsFlowing)
boxplotsFlowing
```

Interpret this color scale with a lot of caution... It is automatically generated and not idea.
```{r, echo=FALSE, fig.height=12, fig.width=10}
huc4Valid <- c('0101', '0102', '0103', '0104', '0105', '0106', '0107', '0108', '0109', '0110',
         '0202', '0203', '0206', '0207', '0208', '0204', '0205',
         '0301', '0302', '0303', '0304', '0305', '0306', '0307', '0308','0309', '0310', '0311', '0312', '0313', '0314', '0315', '0316', '0317', '0318',
         '0401', '0402', '0403', '0404', '0405', '0406', '0407', '0408', '0409', '0410', '0411', '0412', '0413', '0414', '0420', '0427', '0429', '0430',
         '0501', '0502', '0503', '0504', '0505', '0506', '0507', '0508', '0509', '0510', '0511', '0512', '0513', '0514',
         '0601', '0602', '0603', '0604',
         '0701', '0702', '0703', '0704', '0705', '0706', '0707', '0708', '0709', '0710', '0711', '0712', '0713', '0714',
         '0801', '0802', '0803', '0804', '0805', '0806', '0807', '0808', '0809',
         '0901', '0902', '0903', '0904',
         '1002', '1003', '1004', '1005', '1006', '1007', '1008', '1009', '1010', '1011', '1012', '1013', '1014', '1015', #no '1001'
             '1016', '1017', '1018', '1019', '1020', '1021', '1022', '1023', '1024', '1025', '1026', '1027', '1028', '1029', '1030',
         '1101', '1102', '1103', '1104', '1105', '1106', '1107', '1108', '1109', '1110', '1111', '1112', '1113', '1114',
         '1204', '1205', '1208', '1211', '1209', '1210', '1201', '1202', '1203', '1206', '1207',
         '1301', '1302', '1303', '1304', '1305', '1306', '1307', '1308', '1309',
         '1402', '1403', '1406', '1407', '1408', '1401', '1404', '1405',
         '1502', '1504', '1505', '1506', '1507', '1501', '1508', '1503',
         '1601', '1602', '1603', '1605', '1604', '1606',
         '1701', '1702', '1703', '1704', '1705', '1706', '1707', '1708', '1709', '1710', '1711', '1712',
         '1801', '1802', '1803', '1804', '1805', '1806', '1807', '1808', '1809', '1810')
tar_load(shapefile_fin)
forPlot <- dplyr::filter(shapefile_fin$shapefile, huc4 %in% huc4Valid)
ggplot(forPlot, aes(fill=percQ_eph_flowing_scaled)) +
    geom_sf(color='black') +
    viridis::scale_fill_viridis() +
    ggtitle("Streamflow Passing through Ephemeral Channels [%]") +
    theme(legend.position = 'bottom')
```

## **Results: Parameter Sensitivity**
There are specific concerns about model parameters and limitations of process representation at this scale, so set of parameter sensitivity tests are needed. For each one, I outline the goal of the test, the specifics of the test, the expected result if the model is working as hoped, and then the figures plotting the results.

### *Ephemeral Mapping Sensitivity*
*Goal:* Make sure classification accuracy isn't wildly dependent on snapping threshold. It is expected that many of these field assessments were made in streams not actually represented in the NHD, and so we need to determine a reasonable buffer around each river to account for both locational errors and data that shouldn't actually be snapped to the river network.

*Approach:* Compare ephemeral mapping accuracy to the snapping threshold

*Expected:* As snapping threshold increases, accuracy should decrease but also asymptote to a value that will be a bit of an underestimate (given the rational provided in the next test).

```{r, echo=FALSE, fig.height=8, fig.width=9}
tar_load(snappingSensitivityFig)
snappingSensitivityFig$accuracyPlot
```

### *Ephemeral Scaling Sensitivity*
*Goal:* Check which snapping thresholds yield patterns and scaling relationships that are expected 'in the wild'. Again, it is expected that many of these field assessments were made in streams not actually represented in the NHD, and so we need to determine a reasonable buffer around each river to account for both locational errors and data that shouldn't actually be snapped to the river network.

*Approach:* Using the EPA data, check which snapping thresholds yield expected classical/Hortonian scaling across all field-verified ephemeral channels, assuming that Horton's laws hold across all ephemeral channels. This is done by comparing the snapping threshold to 1) strength-of-fit of classical/Hortonian river network scaling theory of ephemeral channels (orange) and 2) the number of orders that would need to be additionally scaled to yield the observed distributions in the EPA WOTUS data (green).
  - Green line: because much of this data is on streams/creeks smaller than those in the NHD, we
    1) Fit the horton law of stream numbers to the EPA/Corps data
    2) Use this equation to find the stream order at which number of streams matches the EPA/Corps data NOT on the NHD. This will be the order that we 'scale down to', assuming that the EPA/Corps data is of sufficient resolution to include the smallest ephemeral channels out there. This is conservative and we are likely still missing some streams.
    3) Calculate MAE across all orders (existing + scaled orders) to determine which snapping thresholds 'best fit the data'. MAE is mean absolute error, with smaller values being 'better'.

*Expected result:* As we increase the snapping threshold, it is expected that MAE (orange) will initially decrease as any locational errors are handled, but then begin increasing again as we begin mis-assigning EPA field data to the wrong rivers. There should also be a range of snapping thresholds where the number of scaled stream orders (green) is reasonably robust. Artifically high or low snapping thresholds should yield sporadic # of scaled orders, while resonable threshlds should all yield ~the same number.

**This analysis is very much in the weeds, but basically we are looking for small orange values and a green value that is insensitive to changes in the snapping threshold**. We also use the previous plot to inform this analysis. This is about 10-15m.
```{r, echo=FALSE, fig.height=8, fig.width=9}
tar_load(snappingSensitivityFig)
snappingSensitivityFig$tradeOffPlot
```

### *Number Flowing Days Sensitivity*
*Goal:* Confirm that reasonable order of magnitude estimates of 'number of flowing days' are sufficient.

*Approach:* Re-run the model under a few runoff scenarios that get increasingly extreme and unlikely. These tests are detaled below:

1) 'Low-runoff scenario': runoff ratio reduced by `r runoffEffScalar_high*100`% and runoff memory of `r runoffMemory_low` days. Representative of low antecedent moisture conditions.
2) 'High-runoff scenario': runoff ratio increased by `r runoffEffScalar_high*100`% and runoff memory of `r runoffMemory_high` days. Representative of high antecedent moisture conditions.

*Expected Result*: Little change in final model results given these runoff perturbations.
```{r, echo=FALSE, fig.height=9, fig.width=9}
tar_load(boxPlotsSensitivity)
boxPlotsSensitivity
```

### *'Calibrating' a streamflow threshold
```{r, echo=FALSE, fig.height=9, fig.width=9}
tar_load(flowingDaysCalibrate)
flowingDaysCalibrate
```
